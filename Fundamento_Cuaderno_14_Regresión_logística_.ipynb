{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amgito1648/clase-inteligencia-artificial/blob/main/Fundamento_Cuaderno_14_Regresi%C3%B3n_log%C3%ADstica_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">Cuaderno 14. Regresión logística </font>\n",
        "## <font color=\"red\">14.1 ¿Qué es la Regresión Logística?</font>\n",
        "La regresión logística es un algoritmo de aprendizaje supervisado utilizado principalmente para problemas de clasificación binaria (dos categorías). Su objetivo es modelar la relación entre un conjunto de variables independientes (predictores) y una variable dependiente categórica. A diferencia de la regresión lineal, el resultado de la regresión logística se interpreta como una probabilidad que oscila entre 0 y 1.\n",
        "\n",
        "Casos donde se aplica\n",
        "* Clasificación de correos electrónicos (spam o no spam).\n",
        "* Diagnóstico médico (enfermedad presente o ausente).\n",
        "* Predicción de abandono de clientes.\n",
        "* Clasificación binaria en cualquier contexto (aprobado/reprobado, verdadero/falso).\n",
        "\n",
        "![imagen](https://images.datacamp.com/image/upload/v1661171230/Logistic_Regression_50731b4db3.png)\n",
        "\n",
        "\n",
        "En la gráfica anerior se aprecia la comparación entre la regresion Lineal y la regresión logística. Así se observa que una regresión lineal no se ajusta bien a una clasificiación de 0 y 1, mientras que la regresión logistica (cuyo resultado se puede analizar como la probabilidad de ser 0 o 1. (0% o 100%) se ajusta de manera adecuada.\n",
        "---\n",
        "\n",
        "\n",
        "## <font color=\"red\">14.2 Formulación Matemática</font>\n",
        "La regresión logística utiliza la función sigmoide o logística para mapear cualquier valor real a un intervalo entre 0 y 1:\n",
        "\n",
        "$h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}$\n",
        "\n",
        "Donde:\n",
        "\n",
        "* $h_\\theta(x)$ representa la probabilidad de que la muestra pertenezca a una clase específica (por ejemplo, clase 1).\n",
        "* $\\theta$ son los parámetros (pesos) aprendidos durante el entrenamiento.\n",
        "* x son las características (variables independientes).\n",
        "\n",
        "\n",
        "El modelo optimiza los parámetros $\\theta$ usando estimación de máxima verosimilitud para encontrar los valores que maximizan la probabilidad de observar los datos dados.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## <font color=\"red\">14.3 Diferencias entre Regresión Logística y Regresión Lineal</font>\n",
        "| **Aspecto**           | **Regresión Lineal**                              | **Regresión Logística**                                         |\n",
        "|------------------------|---------------------------------------------------|-----------------------------------------------------------------|\n",
        "| **Tipo de salida**     | Valor continuo (números reales).                  | Probabilidad (entre 0 y 1).                                     |\n",
        "| **Aplicación**         | Predicción (regresión).                           | Clasificación (binaria o multiclase).                          |\n",
        "| **Función objetivo**   | Minimizar error cuadrático medio (MSE).           | Maximizar la verosimilitud.                                    |\n",
        "| **Forma de la ecuación** | Lineal $( y = \\theta^T x )$.                   | Sigmoide $( h_\\theta(x) = \\frac{1}{1+e^{-\\theta^T x}})$.     |\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## <font color=\"red\">14.4  Estimación de Máxima Verosimilitud</font>\n",
        "La función de costo en regresión logística no es el error cuadrático medio, sino una función basada en la verosimilitud:\n",
        "$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right]$\n",
        "\n",
        "Donde:\n",
        "- $m$: número de muestras.\n",
        "- $y^{(i)}$: etiqueta de la muestra $i$.\n",
        "-$h_\\theta(x^{(i)})$ : predicción para la muestra $i$.\n",
        "\n",
        "\n",
        "Este enfoque asegura que el modelo ajuste las probabilidades predichas a los datos reales.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## <font color=\"red\">14.5 ¿Por qué se dice que la regresión logística regresa una probabilidad?</font>\n",
        "\n",
        "La salida de la función sigmoide es un valor entre 0 y 1, lo que facilita su interpretación como una probabilidad. Por ejemplo:\n",
        "- Si $h_\\theta(x) = 0.8$, hay un 80% de probabilidad de que la muestra pertenezca a la clase positiva.\n",
        "- Si $h_\\theta(x) = 0.3$, hay un 30% de probabilidad de que la muestra pertenezca a la clase positiva.\n",
        "\n",
        "La probabilidad también permite aplicar un umbral (comúnmente 0.5) para decidir a qué clase pertenece una observación.\n",
        "\n",
        "### Ejercicio Sencillo de Clasificación Binaria con Scikit-learn\n",
        "Paso 1: Cargar Datos\n",
        "Usaremos el conjunto de datos Breast Cancer Dataset proporcionado por Scikit-learn, que contiene información sobre características físicas de tumores para predecir si son malignos o benignos.\n",
        "\n",
        "**Pasos del ejercicio**\n",
        "* Cargar los datos y preparar las variables.\n",
        "* Dividir el dataset en conjuntos de entrenamiento y prueba.\n",
        "* Escalar las características para mejorar el rendimiento del modelo.\n",
        "* Entrenar el modelo de regresión logística.\n",
        "* Evaluar el modelo usando métricas de clasificación como la exactitud (accuracy) y el reporte de clasificación.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XMO70z9hsku-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos load_breast_cancer() para cargar los datos. El dataset contiene características de tumores en células de cáncer de mama, como el tamaño, la textura, el perímetro, etc. La etiqueta (y) es binaria: 1 para tumores malignos y 0 para tumores benignos."
      ],
      "metadata": {
        "id": "cJ1U206qzO1o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQzY5MzYrtFh"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Cargar dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame para X con nombres de columnas\n",
        "X_df = pd.DataFrame(X, columns=data.feature_names)\n",
        "\n",
        "# Crear un DataFrame para y con nombre de columna\n",
        "y_df = pd.DataFrame(y, columns=[\"Clase Tumor\"])\n",
        "\n",
        "X_df"
      ],
      "metadata": {
        "id": "70O4kPkN_DA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.columns"
      ],
      "metadata": {
        "id": "d4OiRoBq_kUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame con la variable dependiente 'y' y asignarle un nombre de columna\n",
        "y_df"
      ],
      "metadata": {
        "id": "ebN2EFhs_0_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_df.value_counts()"
      ],
      "metadata": {
        "id": "gMbUSVAMwZtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Barra de value_counts\n",
        "y_df.value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "4wyTGH9Hwz29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cantidad = y_df.value_counts()\n",
        "print(f\"Porcentaje de tumores malignos: {cantidad[1]/cantidad.sum():.2%}\")\n",
        "print(f\"Porcentaje Sin tumores malignos: {cantidad[0]/cantidad.sum():.2%}\")"
      ],
      "metadata": {
        "id": "i4kwm-XqwlC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Diferencia: {cantidad[1]/cantidad.sum()-cantidad[0]/cantidad.sum():.2%}\")"
      ],
      "metadata": {
        "id": "IU0JUz62w5Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que los datos no están significativamente desbalanceados, se puede entrenar sin requerir blanceo."
      ],
      "metadata": {
        "id": "Vy6wVJI6xLL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso** 2: Dividir los datos\n",
        "Dividimos los datos en conjuntos de entrenamiento y prueba.\n"
      ],
      "metadata": {
        "id": "WKeWflsnJpgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.describe()"
      ],
      "metadata": {
        "id": "f883QqVJxaRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coeficiente de correlación con seaborn de las columnas de X_df con los valores\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular la matriz de correlación\n",
        "corr_matrix = X_df.corr()\n",
        "\n",
        "corr_matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "aOswkkzuxfvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#De acuerdo con la tabla anterior los features mean radius, mean perimeter y la mean concavity tiene entre si correlaciones uperiores a 0.8\n",
        "#por lo tanto lo vamos a retirar del dataset.\n",
        "X_df.drop(['mean radius', 'mean perimeter', 'mean concavity','radius error'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "GQPmJMkpyYMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.shape"
      ],
      "metadata": {
        "id": "t4wewvVozNWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42, stratify=y_df)"
      ],
      "metadata": {
        "id": "2IxF66wJJsN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "id": "iT_OSgrJzg2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3: Normalizar las características\n",
        "La normalización es importante en la regresión logística, especialmente si las variables tienen diferentes escalas.\n"
      ],
      "metadata": {
        "id": "uxrNE3R3Jle6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "S1j5Kn2VJnWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Solo por probar vamos a balancear el X_train y Y_train usando SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "-5NJjz-txk8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#barra de y_train_resampled con value_counts\n",
        "y_train.value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "iprft1pixuJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4: Entrenar el modelo\n",
        "Entrenamos un modelo de regresión logística con los datos normalizados.\n"
      ],
      "metadata": {
        "id": "Bf8ObEzbJunc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el modelo de regresión logística\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)"
      ],
      "metadata": {
        "id": "h4Z-qFIAJwV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dado que tenemos ahora 26 caracteristicas, quiero seleccionar solo las 10 más importantes,\n",
        "#Para esto vamos a aplicar RFE para seleccionar características basado en la eliminación de caracteristicas recursivamente\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Usar RFE para seleccionar las 10 características más importantes\n",
        "selector = RFE(model, n_features_to_select=10)\n",
        "X_train_rfe = selector.fit_transform(X_train_scaled, y_train.values.ravel())\n",
        "X_test_rfe = selector.transform(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "pi3nG7zx3qFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_rfe"
      ],
      "metadata": {
        "id": "e909FuFf1mZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizar el modelo a entrenar\n",
        "selector"
      ],
      "metadata": {
        "id": "-b97feWI0Gwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector.n_features_in_\n"
      ],
      "metadata": {
        "id": "aj8CUR6N0ewl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostras los nombre de las caracteristicas seleccionadas de X_df.columns filtrada por selector.support_\n",
        "X_df.columns[selector.support_]"
      ],
      "metadata": {
        "id": "QhDr7vcU1ygr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Obtener el nombre de las columnas"
      ],
      "metadata": {
        "id": "baIgAFqH5ILx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas seleccionadas\n",
        "# Using X_df.columns which has the correct number of features after dropping columns\n",
        "columnas_seleccionadas = X_df.columns[selector.support_]\n",
        "print(\"Columnas seleccionadas por RFE:\")\n",
        "print(\", \".join(columnas_seleccionadas))"
      ],
      "metadata": {
        "id": "N8VsCj_g422l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a reentrenar el escalador con las columnas sugeridas, luego vamos a hacer todo el preprocesamiento.\n"
      ],
      "metadata": {
        "id": "XTB6l1rF6H8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear nuevos DataFrames con las columnas seleccionadas\n",
        "columnas= pd.DataFrame(X_train_rfe, columns=columnas_seleccionadas).columns\n",
        "X_test_rfe_selected = pd.DataFrame(X_test_rfe, columns=columnas_seleccionadas)"
      ],
      "metadata": {
        "id": "E4kwfsWY6HKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar X_df para que contenga solo las 10 columnas seleccionadas\n",
        "X_df = X_df[columnas_seleccionadas]\n",
        "y=y_df"
      ],
      "metadata": {
        "id": "CbMBzL62HZlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_df[y_df['Clase Tumor']==1]"
      ],
      "metadata": {
        "id": "vTkl55d74XlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df[columnas_seleccionadas][19:20]\n"
      ],
      "metadata": {
        "id": "BYT6oPhn4Duo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "R07Nv3WEHr5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "QqYgcFx--4YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalar los datos\n",
        "scaler10 = StandardScaler()\n",
        "X_train_scaled = scaler10.fit_transform(X_train)\n",
        "X_test_scaled = scaler10.transform(X_test)"
      ],
      "metadata": {
        "id": "93HtI2UPH46P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[0]"
      ],
      "metadata": {
        "id": "Cmp0Vi7w3rZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo con las características seleccionadas\n",
        "model.fit(X_train_scaled, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "O95V9NMy3mB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 5: Validar el modelo\n",
        "Evaluamos el modelo con datos de prueba.\n"
      ],
      "metadata": {
        "id": "AuQ8EbPmJxzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo con los datos de prueba\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Resultados\n",
        "print(\"\\nAccuracy con las mejores columnas:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NpCMunngJyvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 6: Mejorar el modelo**\n",
        "\n",
        "\n",
        "* Ajustar hiperparámetros como C (regularización) o max_iter.\n",
        "* Usar técnicas de selección de características como Recursive Feature Elimination (RFE).\n",
        "\n",
        "Ejemplo de selección de características:\n"
      ],
      "metadata": {
        "id": "GM2QijNgJ2q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se muestra cómo podemos implementar GridSearchCV para encontrar el mejor modelo de regresión logística con los resultados anteriores, utilizando la selección de características mediante RFE.\n",
        "\n",
        "Pasos para implementar GridSearchCV:\n",
        "Definir los hiperparámetros que deseamos probar.\n",
        "Usar GridSearchCV para probar todas las combinaciones de esos hiperparámetros.\n",
        "Evaluar el mejor modelo basado en la métrica de evaluación.\n",
        "\n",
        "\n",
        "**Mejores hiperparámetros:** Te mostrará la mejor combinación de hiperparámetros encontrados por GridSearchCV.\n",
        "**Exactitud:** Te proporcionará la exactitud del modelo con los mejores hiperparámetros en los datos de prueba.\n",
        "**Reporte de clasificación:** Incluirá métricas como la precisión, recall y F1-score.\n",
        "**Predicción **para un nuevo dato: Mostrará el resultado de la predicción para un dato que se introduzca manualmente."
      ],
      "metadata": {
        "id": "vNNvsFBE0J-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.shape"
      ],
      "metadata": {
        "id": "Ky3_PjQVJrKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir los parámetros para GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Regularización (coeficiente)\n",
        "    'solver': ['liblinear', 'saga'],  # Algoritmos de optimización\n",
        "    'penalty': ['l2'],  # Tipo de regularización\n",
        "    'max_iter': [100, 200, 300,500,1000]  # Número máximo de iteraciones\n",
        "}\n",
        "\n",
        "# Inicializar GridSearchCV con validación cruzada\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,  # Modelo base (LogisticRegression)\n",
        "    param_grid=param_grid,\n",
        "    cv=5,  # Validación cruzada de 5 particiones\n",
        "    scoring='accuracy',  # Métrica para optimizar\n",
        "    n_jobs=-1  # Usar todos los núcleos disponibles\n",
        ")\n",
        "\n",
        "# Realizar la búsqueda de hiperparámetros\n",
        "grid_search.fit(X_train_scaled,y_train.values.ravel())\n"
      ],
      "metadata": {
        "id": "6xWUcOJw0LF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejor modelo encontrado\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Mejores hiperparámetros encontrados por GridSearchCV:\")\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "id": "DGL0Wdjr1_ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Guardar el modelo entrenado usando joblib\n",
        "joblib.dump(best_model, 'mejor_modelo_logistico.joblib')\n",
        "\n",
        "# Evaluar el modelo con los datos de prueba\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Resultados\n",
        "print(\"Mejores hiperparámetros encontrados por GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n"
      ],
      "metadata": {
        "id": "cpfWxyZW2DwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAccuracy con los mejores hiperparámetros:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "rOsnoiGz2d-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV **realiza una búsqueda exhaustiva sobre un conjunto de valores posibles para cada uno de estos hiperparámetros y evalúa qué combinación de ellos da el mejor rendimiento según el criterio que tú elijas (en este caso, accuracy, o precisión). Luego, elige la combinación de parámetros que da el mejor rendimiento en las validaciones cruzadas.\n",
        "\n",
        "En resumen, los mejores hiperparámetros encontrados por GridSearchCV para este modelo de regresión logística son:\n",
        "\n",
        "C = 1: Regularización moderada.\n",
        "max_iter = 100: El modelo convergerá en 100 iteraciones.\n",
        "penalty = 'l2': Se usa regularización L2 (Ridge).\n",
        "solver = 'liblinear': El solver de optimización más eficiente para este problema."
      ],
      "metadata": {
        "id": "-oGpC1dYF-l1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo de predicción con un nuevo dato"
      ],
      "metadata": {
        "id": "FQmoQwus0Z5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cargar el mejor modelo entrenado\n",
        "best_model = joblib.load('mejor_modelo_logistico.joblib')\n",
        "\n",
        "# Las 10 columnas seleccionadas por RFE\n",
        "columnas_seleccionadas = ['mean area', 'perimeter error', 'area error', 'worst radius',\n",
        "       'worst texture', 'worst perimeter', 'worst area', 'worst smoothness',\n",
        "       'worst concavity', 'worst concave points']\n",
        "\n",
        "# Cargar el dataset original (asegúrate de que estás trabajando con el mismo dataset que usaste para entrenar)\n",
        "data = load_breast_cancer()\n",
        "X_df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Filtrar el dataset para que contenga solo las 10 características seleccionadas por RFE\n",
        "X_selected = X_df[columnas_seleccionadas]\n",
        "\n",
        "\n",
        "# Nuevo dato para hacer la predicción (asegúrate de que tenga 10 características)\n",
        "nuevo_dato = np.array([[250.5,1.8850,17.67,10.310,22.65,65.50,324.7,0.14820,1.25200,0.17500]])\n",
        "\n",
        "# Convertir el nuevo dato a un DataFrame con las columnas seleccionadas\n",
        "nuevo_dato_df = pd.DataFrame(nuevo_dato, columns=columnas_seleccionadas)\n",
        "\n",
        "# Escalar el nuevo dato\n",
        "nuevo_dato_scaled = scaler10.transform(nuevo_dato_df)\n",
        "\n",
        "# Realizar la predicción\n",
        "prediccion = best_model.predict(nuevo_dato_scaled)\n",
        "\n",
        "# Interpretar y mostrar la predicción\n",
        "if prediccion <= 0.5:\n",
        "    print(\"\\nEl modelo predice que el tumor es BENIGNO (clase 0).\")\n",
        "else:\n",
        "    print(\"\\nEl modelo predice que el tumor es MALIGNO (clase 1).\")\n"
      ],
      "metadata": {
        "id": "eKPw1fQg0psu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#El valor de prediccio en porcentaje de probabilidad\n",
        "\n",
        "prediccion_probabilidad = best_model.predict_proba(nuevo_dato_scaled)\n",
        "# Access the individual probabilities within the array and format them\n",
        "prob_benigno, prob_maligno = prediccion_probabilidad[0]\n",
        "print(f\"Probabilidad Benigno: {prob_benigno*100:.2f}%\")\n",
        "print(f\"Probabilidad Maligno: {prob_maligno*100:.2f}%\")"
      ],
      "metadata": {
        "id": "gyHY1bKu2yFw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}