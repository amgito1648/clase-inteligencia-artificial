{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amgito1648/clase-inteligencia-artificial/blob/main/Fundamento_Cuaderno_11_%C3%81rboles_de_Decisi%C3%B3n_para_Clasificaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4UQkucY1sPn"
      },
      "source": [
        "# <font color=\"red\">Cuaderno 11. Árboles de Decisión para Clasificación y regresión\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## <font color=\"red\">11.1 Introducción\n",
        "Los árboles de decisión para clasificación y regresión son una técnica poderosa en el campo del aprendizaje supervisado. Se utilizan para predecir una variable categórica (o clase) a partir de un conjunto de variables predictoras. En lugar de seguir una fórmula matemática única, estos modelos dividen el espacio de los predictores en subregiones que son más homogéneas respecto a la clase objetivo. Esto se hace mediante una serie de decisiones binarias, basadas en los valores de los atributos, que conducen a un nodo terminal (hoja), donde se hace la predicción.\n",
        "\n",
        "El proceso de construcción de un árbol de decisión incluye la selección de puntos de corte o raiz en las variables para dividir el espacio muestral en subconjuntos. Existen varias estrategias para la creación de estos árboles, siendo las más comunes el Criterio de Impureza de Gini, la Entropía y el Cálculo de la Varianza. Los árboles de decisión pueden mejorar su desempeño mediante métodos como Random Forest y Gradient Boosting, que veremos en los siguiente cuadernos, estoa combinan múltiples árboles para reducir el sobreajuste (overfitting) y mejorar la generalización del modelo, llamados modelos ensamblados.\n",
        "\n",
        "\n",
        "## <font color=\"red\">11.2 ¿Cómo funciona un árbol de decisión para clasificación?\n",
        "Un árbol de decisión clasifica una observación siguiendo una serie de divisiones binarias basadas en las características de la muestra. El árbol comienza en un nodo raíz, donde se evalúan las características de los datos. A partir de ahí, las observaciones se dividen en diferentes ramas según las condiciones específicas establecidas para cada característica. Este proceso continúa hasta llegar a un nodo terminal, que es el que asigna una clase a la observación.\n",
        "\n",
        "![imagen](https://github.com/adiacla/bigdata/blob/master/arbol.png?raw=true)\n",
        "\n",
        "Como se muestra en la imagen un nodo raiz se crea con un criterio de regla de decisión para aquel cuya horas de estudio son menores o iguales a 0.5 y mayores.\n",
        "Así sucesivamente el arbol irá creando ramas de manera recursiva hasta llegar a las hojas donde asigna la etiquete a los registros que cumplen la condición.\n",
        "\n",
        "* División inicial: En el nodo raíz, el árbol evalúa la primera condición, por ejemplo, si el valor de una variable es mayor o menor que un umbral específico.\n",
        "\n",
        " Dependiendo del resultado, la observación se dirige por una rama a otro nodo.\n",
        "\n",
        "* División recursiva: El proceso de división continúa recursivamente en cada nuevo nodo. En cada nodo, se evalúa una nueva condición para una característica diferente.\n",
        "\n",
        "* Nodo terminal: Cuando ya no es posible dividir más las observaciones (o cuando se alcanza un umbral de profundidad del árbol), el nodo terminal asigna la clase más frecuente entre las observaciones que llegaron a ese nodo.\n",
        "\n",
        "### <font color=\"blue\">11.2.1 Métodos para seleccionar las divisiones\n",
        "\n",
        "Para decidir en qué punto dividir las observaciones, se utilizan criterios de división. Los más comunes son:\n",
        "\n",
        "* **Gini Impurity:** Mide la impureza de un nodo. Cuanto menor sea la impureza, más homogénea será la clase en ese nodo. El objetivo es dividir el nodo de manera que las subregiones sean lo más puras posibles, es decir, que todas las observaciones dentro de un nodo terminal pertenezcan a la misma clase.\n",
        "\n",
        "  Formula del Gini Impurity para una clase $K$ es:\n",
        "\n",
        "  $Gini(t) = 1 - ∑_{k=1}^{K} p_k^2$\n",
        "\n",
        "  donde $p_k$ es la proporción de observaciones de la clase $k$ en el nodo $t$.\n",
        "\n",
        "* **Entropía (Cruzada de Shannon)**: La entropía mide la cantidad de desorden o incertidumbre en una división. La idea es reducir la entropía de un conjunto de datos mediante la división en nodos más homogéneos.\n",
        "La fórmula de la entropía es:\n",
        "  $Entropía(t) = - ∑_{k=1}^{K} p_k \\log_2(p_k)$\n",
        "\n",
        "  donde $p_k$ es la probabilidad de observar la clase $k$ en el nodo $t$.\n",
        "\n",
        "* **Índice de Gini vs Entropía**: Ambos criterios se utilizan para elegir el mejor punto de corte, aunque el índice de Gini es más popular debido a su simplicidad y rapidez computacional. Sin embargo, la entropía tiende a ser más informativa en divisiones con muchas clases.\n",
        "\n",
        "### <font color=\"blue\">11.2.2 Ventajas de los árboles de decisión para clasificación\n",
        "* Interpretabilidad: Los árboles de decisión son modelos muy fáciles de interpretar y visualizar. Cada nodo y rama representan una regla de decisión que puede explicarse fácilmente.\n",
        "* No requieren normalización de los datos: A diferencia de otros modelos como las máquinas de soporte vectorial (SVM) o las regresiones lineales, los árboles de decisión no requieren que los datos sean normalizados o estandarizados.\n",
        "* Manejo de datos categóricos y numéricos: Los árboles pueden manejar tanto variables numéricas como categóricas sin necesidad de transformarlas (por ejemplo, a variables dummy).\n",
        "* Resistencia a los valores atípicos: Los árboles no se ven muy afectados por outliers, ya que los puntos extremos no suelen influir en el valor de la división.\n",
        "* Automática selección de variables importantes: Los árboles de decisión pueden identificar qué variables son más relevantes para la clasificación.\n",
        "\n",
        "### <font color=\"blue\">11.2.3 Desventajas de los árboles de decisión para clasificación\n",
        "* Overfitting: Los árboles de decisión tienden a sobreajustarse a los datos de entrenamiento, especialmente cuando se permiten árboles muy profundos. Esto se debe a que pueden aprender detalles muy específicos que no generalizan bien a nuevos datos.\n",
        "* Inestabilidad: Un pequeño cambio en los datos de entrenamiento puede llevar a una estructura de árbol completamente diferente.\n",
        "* Modelo sesgado en clases desbalanceadas: Si los datos están desbalanceados, el árbol puede predecir predominantemente la clase mayoritaria.\n",
        "\n",
        "\n",
        "#### <font color=\"blue\">11.2.4 Estrategias para evitar el overfitting\n",
        "Existen varias técnicas que se pueden aplicar para reducir el sobreajuste en árboles de decisión:\n",
        "* Poda (Pruning): La poda elimina ramas del árbol que tienen poca importancia o que sobreajustan los datos. Se pueden usar métodos como el Cost Complexity Pruning para realizar una poda que elimine ramas que no mejoren significativamente la precisión del modelo.\n",
        "* Limitación de la profundidad del árbol: Limitar la profundidad máxima del árbol es una forma sencilla de evitar que el árbol crezca demasiado, lo que podría llevar a un sobreajuste.\n",
        "* Mínimo número de muestras por hoja: Establecer un número mínimo de observaciones para permitir una división en cada nodo o para que un nodo sea terminal puede ayudar a evitar divisiones demasiado específicas.\n",
        "* Métodos de ensamblaje: Técnicas como Random Forest y Gradient Boosting combinan múltiples árboles de decisión para mejorar la robustez y reducir el riesgo de sobreajuste.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## <font color=\"red\">11.3 Ejercicio de Construcción, Evaluación y Visualización de un Árbol de Decisión para Clasificación\n",
        "\n",
        "En este ejercicio vamos a usar las librerias de sklearn sklearn.tree (https://scikit-learn.org/stable/api/sklearn.tree.html)\n",
        "\n",
        "#### Paso 1:  Preparación del conjunto de datos y codificación\n",
        "Primero, creamos el conjunto de datos con variables categóricas y las codificamos para que puedan ser utilizadas en el modelo.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi1CG3j11hJL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Crear el conjunto de datos\n",
        "data = {\n",
        "    \"Horas de Estudio\": [\"Alta\", \"Baja\", \"Baja\", \"Alta\", \"Alta\",\"Baja\", \"Alta\", ],\n",
        "    \"Asistencia\": [\"Buena\", \"Buena\", \"Mala\", \"Mala\", \"Buena\",\"Buena\", \"Mala\",],\n",
        "    \"Resultado\": [\"Sí\", \"No\", \"No\", \"Sí\", \"Sí\",\"No\", \"No\",]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mMFGZbffeOT"
      },
      "outputs": [],
      "source": [
        "# Codificar variables categóricas a numéricas\n",
        "encoder = LabelEncoder()\n",
        "df_encoded = df.apply(encoder.fit_transform)\n",
        "\n",
        "# Separar características y etiqueta\n",
        "X = df_encoded[[\"Horas de Estudio\", \"Asistencia\"]]\n",
        "y = df_encoded[\"Resultado\"]\n",
        "\n",
        "\n",
        "#Dado que son muy pocos datos no vamos a dividir en entrenamiento y pruebas, usaremos la data tanto para entrenar como para probar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7yfcAsRuYSr"
      },
      "outputs": [],
      "source": [
        "print(X)\n",
        "print(\"\\n\")\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dnPHX2j4WdH"
      },
      "source": [
        "### Paso 2: Entrenamiento del Árbol de Decisión\n",
        "Ahora, entrenamos un Árbol de Decisión utilizando el conjunto de entrenamiento y hacemos las predicciones en el conjunto de prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4YpE1hj4Zh1"
      },
      "outputs": [],
      "source": [
        "# Crear el modelo de Árbol de Decisión\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X, y)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = tree_clf.predict(X)\n",
        "\n",
        "# Evaluación del modelo\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "conf_matrix = confusion_matrix(y, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w6gDnMx_fQJ"
      },
      "outputs": [],
      "source": [
        "# Imprimir los resultados\n",
        "print(\"Precisión del modelo:\", accuracy)\n",
        "print(\"Matriz de confusión:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdgmPo7etEmG"
      },
      "outputs": [],
      "source": [
        "# Verificar si hay más de una clase en y_test para calcular el ROC AUC\n",
        "if len(np.unique(y)) > 1:\n",
        "    roc_auc = roc_auc_score(y, tree_clf.predict_proba(X)[:, 1])\n",
        "else:\n",
        "    roc_auc = \"No se puede calcular ROC AUC (solo una clase en y_test)\"\n",
        "\n",
        "\n",
        "print(\"Área bajo la curva ROC:\", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4EWaAmUtRA9"
      },
      "outputs": [],
      "source": [
        "#Grafique la matriz confusión en mapa de calor con seaborn\n",
        "import seaborn as sns\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3U3Ub1m4cTd"
      },
      "source": [
        "### Paso 3: Visualización del Árbol de Decisión\n",
        "A continuación, visualizamos el árbol de decisión entrenado para entender cómo se están realizando las predicciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCiOD7gq4f_N"
      },
      "outputs": [],
      "source": [
        "# Graficar el árbol de decisión\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_tree(tree_clf, filled=True, feature_names=[\"Horas de Estudio\", \"Asistencia\"], class_names=[\"No\", \"Sí\"], rounded=True, fontsize=12)\n",
        "plt.title(\"Árbol de Decisión\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwqMwVBX180R"
      },
      "outputs": [],
      "source": [
        "!pip install eli5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdfCsOrk11kM"
      },
      "outputs": [],
      "source": [
        "#usar ELI5 para explicar el arbol entrenado\n",
        "\n",
        "import eli5\n",
        "from eli5.sklearn import explain_weights\n",
        "# Assuming 'tree_clf' and 'X' are defined as in the provided code\n",
        "# ... (your existing code) ...\n",
        "\n",
        "\n",
        "# Explicar los pesos del modelo\n",
        "# The line below was changed to call the explain_weights function correctly.\n",
        "explanation = eli5.explain_weights(tree_clf, feature_names=[\"Horas de Estudio\", \"Asistencia\"])\n",
        "explanation\n",
        "\n",
        "\n",
        "# You can also explain a prediction for a single instance:\n",
        "# Example: explain the prediction for the first instance in X\n",
        "# explanation_instance = eli5.explain_prediction(tree_clf, X.iloc[0], target_names=[\"No\", \"Sí\"], feature_names=[\"Horas de Estudio\", \"Asistencia\"])\n",
        "# print(explanation_instance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcMRqvbc21mv"
      },
      "outputs": [],
      "source": [
        "probabilidad = best_tree.predict_proba(pacientes_nuevos)\n",
        "# Get the class with highest probability\n",
        "predicted_class = np.argmax(probabilidad[0])\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"\\nPredicted Class para la pimera instancia: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-X1HFzc4i79"
      },
      "source": [
        "### Paso 4: Curva ROC\n",
        "Finalmente, calculamos y graficamos la curva ROC para evaluar el rendimiento del modelo a través de diferentes umbrales de clasificación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGFA4K944k-z"
      },
      "outputs": [],
      "source": [
        "# Curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y, tree_clf.predict_proba(X)[:, 1])\n",
        "plt.plot(fpr, tpr, color='blue')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Tasa de Falsos Positivos')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyPy2Rmi4ncN"
      },
      "source": [
        "### Resumen de los resultados\n",
        "Precisión del modelo: Calculada con la función accuracy_score.\n",
        "\n",
        "Matriz de confusión: Evaluación detallada de las predicciones (verdaderos positivos, falsos positivos, etc.).\n",
        "\n",
        "Área bajo la curva ROC: Medida de rendimiento del modelo en función de su capacidad para distinguir entre las clases.\n",
        "\n",
        "Curva ROC: Visualización gráfica del rendimiento del modelo con diferentes umbrales de decisión.\n",
        "\n",
        "---\n",
        "\n",
        "## <font color=\"red\">11.5 Segundo ejercicio con Arboles de Decisión el tema de problemas cardiacos\n",
        "\n",
        "### Paso 1: Cargar y preprocesar los datos\n",
        "Primero, cargamos el conjunto de datos, verificamos los valores faltantes y luego realizamos la imputación de los valores faltantes con la mediana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfXssAfM5qU5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "url = \"https://raw.githubusercontent.com/adiacla/bigdata/refs/heads/master/pacientes.csv\"\n",
        "df_patients = pd.read_csv(url)\n",
        "\n",
        "df_patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzpWtQXHeOKB"
      },
      "outputs": [],
      "source": [
        "df_patients.problema_cardiaco.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmhyW9D4sk-0"
      },
      "outputs": [],
      "source": [
        "df_patients.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afFioqYCbZGi"
      },
      "outputs": [],
      "source": [
        "df_patients.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBBOnDzMgasq"
      },
      "outputs": [],
      "source": [
        "# Separar las características y la etiqueta\n",
        "X = df_patients.drop(columns=[label_col_name])\n",
        "y = df_patients[label_col_name]\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"División de datos completada:\")\n",
        "print(f\"Entrenamiento: {X_train.shape[0]} registros\")\n",
        "print(f\"Prueba: {X_test.shape[0]} registros\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qElK3oSC5s9C"
      },
      "source": [
        "### Paso 2: Entrenamiento del Árbol de Decisión\n",
        "Entrenamos un Árbol de Decisión con el conjunto de entrenamiento. Para la clasificación, utilizamos el DecisionTreeClassifier de Scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtsLbYCc5uyP"
      },
      "outputs": [],
      "source": [
        "# Crear el modelo de Árbol de Decisión\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = tree_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtdO46Lv6DP6"
      },
      "source": [
        "### Paso 3: Evaluación del modelo\n",
        "Evaluamos el rendimiento del modelo utilizando varias métricas: precisión, matriz de confusión y área bajo la curva ROC (AUC). También graficamos la curva ROC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyodfdtD6Fw6"
      },
      "outputs": [],
      "source": [
        "# Evaluación del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, tree_clf.predict_proba(X_test)[:, 1])\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Exactitud del modelo:\", accuracy)\n",
        "print(\"Matriz de confusión:\\n\", conf_matrix)\n",
        "print(\"Área bajo la curva ROC:\", roc_auc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rjzdGVThcul"
      },
      "outputs": [],
      "source": [
        "# Curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, tree_clf.predict_proba(X_test)[:, 1])\n",
        "plt.plot(fpr, tpr, color='blue')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Tasa de Falsos Positivos')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI-0g5Ofu5M7"
      },
      "outputs": [],
      "source": [
        "#Dibujamos la matriz de confusión con seaborn con mapa de calor\n",
        "import seaborn as sns\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWrEpNTR6KWK"
      },
      "source": [
        "### Paso 4: Visualización del Árbol de Decisión\n",
        "Utilizamos la función plot_tree para visualizar el árbol de decisión y entender cómo se toman las decisiones en función de las características.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7avnasfk6NEq"
      },
      "outputs": [],
      "source": [
        "# Graficar el árbol de decisión\n",
        "plt.figure(figsize=(30, 30))\n",
        "plot_tree(tree_clf, filled=True, feature_names=X.columns, class_names=['No','Si'], rounded=True, fontsize=12)\n",
        "plt.title(\"Árbol de Decisión\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs0nbr5S6Ooy"
      },
      "source": [
        "### Resumen del flujo:\n",
        "Carga y preprocesamiento: Se cargan los datos y se manejan los valores faltantes (con la mediana), y se convierten las variables categóricas a numéricas.\n",
        "\n",
        "Entrenamiento: El modelo de Árbol de Decisión es entrenado utilizando el conjunto de entrenamiento.\n",
        "\n",
        "Evaluación: Se calcula la precisión, la matriz de confusión y el área bajo la curva ROC para evaluar el rendimiento del modelo.\n",
        "\n",
        "Visualización: Se visualiza el árbol de decisión para interpretar cómo se toman las decisiones.\n",
        "\n",
        "\n",
        "Tal como se visualiza el modelo pareciera que puede estar sobre entrenado, es quede predice en un arbol que llega a su maxima profundidad, por lo tanto\n",
        "Para evitar el sobreajuste en un modelo de Árbol de Decisión, puedes usar varios enfoques como limitar la profundidad del árbol, ajustar el número mínimo de muestras necesarias para dividir un nodo, o establecer un criterio de complejidad. Aquí te dejo algunas variantes del código que puedes implementar para controlar el sobreajuste:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdXARx_XhsEr"
      },
      "source": [
        "***Limitar la profundidad máxima del árbol***\n",
        "Reducir la profundidad del árbol asegura que no crezca demasiado y evita que modele ruido en los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H64SVWg7hNwN"
      },
      "outputs": [],
      "source": [
        "tree_clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred = tree_clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrn-C0Y4h5g_"
      },
      "source": [
        "*** Aumentar el número mínimo de muestras*** para dividir un nodo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InmvWuiqhv8S"
      },
      "outputs": [],
      "source": [
        "tree_clf = DecisionTreeClassifier(min_samples_split=10, random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred = tree_clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ARthm3VkzcR"
      },
      "source": [
        "***Establecer un umbral mínimo para la ganancia de información***\n",
        "\n",
        "min_impurity_decrease requiere que una división reduzca la impureza por una cantidad mínima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPqeTwZzhcvq"
      },
      "outputs": [],
      "source": [
        "tree_clf = DecisionTreeClassifier(min_impurity_decrease=0.01, random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred = tree_clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14n38B31k9ZM"
      },
      "source": [
        "***Podar el árbol mediante la complejidad de costo***\n",
        "\n",
        "ccp_alpha (Cost Complexity Pruning) permite podar ramas menos importantes que no reducen mucho el error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhiAFk_HlFpy"
      },
      "outputs": [],
      "source": [
        "tree_clf = DecisionTreeClassifier(ccp_alpha=0.01, random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred = tree_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_O-XGZwlH9G"
      },
      "source": [
        "*** Validación cruzada para optimizar hiperparámetros***\n",
        "Puedes usar GridSearchCV para buscar los mejores parámetros que eviten el sobreajuste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_f2I5oVwlPom"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': np.arange(5, 14),\n",
        "    'min_samples_split': [2, 3, 4,5,6,7],\n",
        "    'min_samples_leaf': [1, 2,3,4,5],\n",
        "    'criterion':['gini', 'entropy', 'log_loss'],\n",
        "    'splitter': ['best', 'random']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_tree = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UpRjT0lS1s"
      },
      "source": [
        "***Vamos a entrenar el modelo con los mejores parámetros***\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2QiFwrwFlYpS"
      },
      "outputs": [],
      "source": [
        "y_pred = best_tree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sD2Umx6TrnJP"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HAWXS1b0rpGX"
      },
      "outputs": [],
      "source": [
        "y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "328c_C8BlldA"
      },
      "source": [
        "***Evaluación del Modelo***\n",
        "Después de implementar estas variantes, evalúa el modelo con métricas como precisión, matriz de confusión y ROC-AUC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fobdCxSnlha-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Precisión:\", accuracy)\n",
        "print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
        "\n",
        "# Calcular el AUC-ROC si hay al menos dos clases\n",
        "if len(np.unique(y_test)) > 1:\n",
        "    roc_auc = roc_auc_score(y_test, tree_clf.predict_proba(X_test)[:, 1])\n",
        "    print(\"Área bajo la curva ROC:\", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ESsopXkm19Fj"
      },
      "outputs": [],
      "source": [
        "#Dibujamos la matriz de confusión con seaborn con mapa de calor\n",
        "import seaborn as sns\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oJbHzcpD2MPb"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "tree.plot_tree(tree_clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dsqTtyxl27nD"
      },
      "outputs": [],
      "source": [
        "#Realizar la predición de una persona que tiene 35 años de edad y colesterol de 220 si va a usfir de probleas cardiacos usando tree_clf\n",
        "pacientes_nuevos=pd.DataFrame({'edad': [55,64,60], 'colesterol': [240,180,210]},)\n",
        "pacientes_nuevos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FrlcCMqjuXxm"
      },
      "outputs": [],
      "source": [
        "estado = best_tree.predict(pacientes_nuevos)\n",
        "print(estado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUBuYy0uyNWy"
      },
      "outputs": [],
      "source": [
        "resultado=list(map(lambda x: 'Si' if x==1 else 'No', estado))\n",
        "resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PCo9vGn17a4R"
      },
      "outputs": [],
      "source": [
        "#Determinemos la probabilidad de pertenecer a una clase\n",
        "probabilidad = best_tree.predict_proba(pacientes_nuevos)\n",
        "probabilidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sKGeQ-we2mPU"
      },
      "outputs": [],
      "source": [
        "# Graficar el árbol de decisión\n",
        "plt.figure(figsize=(30, 30))\n",
        "plot_tree(best_tree, filled=True, feature_names=X.columns, class_names=['No','Si'], rounded=True, fontsize=12)\n",
        "plt.title(\"El mejor Árbol de Decisión\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}